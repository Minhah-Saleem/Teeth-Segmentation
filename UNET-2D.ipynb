{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291ef014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a898501",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fe12fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(42)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175a7d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import nibabel.orientations as nio\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from skimage import io\n",
    "from patchify import patchify, unpatchify\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import glob\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "from PIL import Image, ImageDraw\n",
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed3e3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function and coefficients to be used during training:\n",
    "def dice_coe(y_true,y_pred, loss_type='jaccard', smooth=1.):\n",
    "\n",
    "    y_true_f = tf.reshape(y_true,[-1])\n",
    "    y_pred_f = tf.reshape(y_pred,[-1])\n",
    "\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "\n",
    "    if loss_type == 'jaccard':\n",
    "        union = tf.reduce_sum(tf.square(y_pred_f)) + tf.reduce_sum(tf.square(y_true_f))\n",
    "\n",
    "    elif loss_type == 'sorensen':\n",
    "        union = tf.reduce_sum(y_pred_f) + tf.reduce_sum(y_true_f)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown `loss_type`: %s\" % loss_type)\n",
    "\n",
    "    return (2. * intersection + smooth) / (union + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81adfd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(y_true,y_pred, loss_type='jaccard', smooth=1.):\n",
    "\n",
    "    y_true_f = tf.cast(tf.reshape(y_true,[-1]),tf.float32)\n",
    "    y_pred_f =tf.cast(tf.reshape(y_pred,[-1]),tf.float32)\n",
    "\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "\n",
    "    if loss_type == 'jaccard':\n",
    "        union = tf.reduce_sum(tf.square(y_pred_f)) + tf.reduce_sum(tf.square(y_true_f))\n",
    "\n",
    "    elif loss_type == 'sorensen':\n",
    "        union = tf.reduce_sum(y_pred_f) + tf.reduce_sum(y_true_f)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown `loss_type`: %s\" % loss_type)\n",
    "\n",
    "    return (1-(2. * intersection + smooth) / (union + smooth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846c3611",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = 'sigmoid'\n",
    "patch_size_x =1120 # should be a multiple of 32 \n",
    "patch_size_y =1120\n",
    "n_classes = 1\n",
    "channels=3\n",
    "\n",
    "LR = 0.0001\n",
    "optim = tf.keras.optimizers.Adam(LR)\n",
    "# optim = tf.keras.optimizers.SGD(LR, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a606cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Conv2D, Input, MaxPooling2D, Dropout, concatenate, UpSampling2D, BatchNormalization\n",
    "import tensorflow as tf\n",
    "\n",
    "def Unet2D(inputs,num_classes):\n",
    "    x=inputs\n",
    "    conv1 = Conv2D(8, 3, activation = 'relu', padding = 'same',data_format=\"channels_last\")(x)\n",
    "    conv1= BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(8, 3, activation = 'relu', padding = 'same')(conv1)\n",
    "    conv1= BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(16, 3, activation = 'relu', padding = 'same')(pool1)\n",
    "    conv2= BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(16, 3, activation = 'relu', padding = 'same')(conv2)\n",
    "    conv2= BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(32, 3, activation = 'relu', padding = 'same')(pool2)\n",
    "    conv3= BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(32, 3, activation = 'relu', padding = 'same')(conv3)\n",
    "    conv3= BatchNormalization()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(64, 3, activation = 'relu', padding = 'same')(pool3)\n",
    "    conv4= BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(64, 3, activation = 'relu', padding = 'same')(conv4)\n",
    "    conv4= BatchNormalization()(conv4)\n",
    "    drop4 = Dropout(0.01)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(128, 3, activation = 'relu', padding = 'same')(pool4)\n",
    "    conv5= BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(128, 3, activation = 'relu', padding = 'same')(conv5)\n",
    "    conv5= BatchNormalization()(conv5)\n",
    "    drop5 = Dropout(0.01)(conv5)\n",
    "    up6 = Conv2D(64, 2, activation = 'relu', padding = 'same')(UpSampling2D(size = (2,2))(drop5))\n",
    "    up6= BatchNormalization()(up6)\n",
    "    merge6 = concatenate([drop4,up6],axis=-1)\n",
    "    conv6 = Conv2D(64, 3, activation = 'relu', padding = 'same')(merge6)\n",
    "    conv6= BatchNormalization()(conv6)\n",
    "    conv6 = Conv2D(64, 3, activation = 'relu', padding = 'same')(conv6)\n",
    "    conv6= BatchNormalization()(conv6)\n",
    "\n",
    "    up7 = Conv2D(32, 2, activation = 'relu', padding = 'same')(UpSampling2D(size = (2,2))(conv6))\n",
    "    up7= BatchNormalization()(up7)\n",
    "    merge7 = concatenate([conv3,up7],axis=-1)\n",
    "    conv7 = Conv2D(32, 3, activation = 'relu', padding = 'same')(merge7)\n",
    "    conv7= BatchNormalization()(conv7)\n",
    "    conv7 = Conv2D(32, 3, activation = 'relu', padding = 'same')(conv7)\n",
    "    conv7= BatchNormalization()(conv7)\n",
    "\n",
    "    up8 = Conv2D(16, 2, activation = 'relu', padding = 'same')(UpSampling2D(size = (2,2))(conv7))\n",
    "    up8= BatchNormalization()(up8)\n",
    "    merge8 = concatenate([conv2,up8],axis=-1)\n",
    "    conv8 = Conv2D(16, 3, activation = 'relu', padding = 'same')(merge8)\n",
    "    conv8= BatchNormalization()(conv8)\n",
    "    conv8 = Conv2D(16, 3, activation = 'relu', padding = 'same')(conv8)\n",
    "    conv8= BatchNormalization()(conv8)\n",
    "\n",
    "    up9 = Conv2D(8, 2, activation = 'relu', padding = 'same')(UpSampling2D(size = (2,2))(conv8))\n",
    "    up9= BatchNormalization()(up9)\n",
    "    merge9 = concatenate([conv1,up9],axis=-1)\n",
    "    conv9 = Conv2D(8, 3, activation = 'relu', padding = 'same')(merge9)\n",
    "    conv9= BatchNormalization()(conv9)\n",
    "    conv9 = Conv2D(8, 3, activation = 'relu', padding = 'same')(conv9)\n",
    "    conv9= BatchNormalization()(conv9)\n",
    "#     conv10 = Conv3D(1, 1, activation = 'sigmoid')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "    model = Model(inputs=inputs, outputs = conv10)\n",
    "    #model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9030bc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(patch_size_x,patch_size_y, channels))\n",
    "# mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:2\"]) \n",
    "\n",
    "# with mirrored_strategy.scope():\n",
    "Model_2D = Unet2D(inputs,num_classes=n_classes)\n",
    "Model_2D.compile(optimizer=optim, loss=dice_loss, metrics=[dice_coe])\n",
    "Model_2D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac658295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras import backend as K\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "def parse_image(img_path, image_size):\n",
    "    image_rgb = cv2.resize((np.array(Image.open(img_path))).astype('float32'), (1120,1120)) #.jpg\n",
    "    train_img = image_rgb.copy()\n",
    "    return train_img\n",
    "\n",
    "def parse_mask(mask_path, image_size):\n",
    "    mask=np.array(Image.open(mask_path))\n",
    "    mask=np.where(mask,1,0)\n",
    "    nm = cv2.resize((mask.astype('float32')), (1120,1120)) #.jpg\n",
    "    train_mask = np.expand_dims(nm, axis=2)\n",
    "    return train_mask\n",
    "\n",
    "\n",
    "class DataGen(Sequence):\n",
    "    def __init__(self, image_size, images_path, masks_path, batch_size=8):\n",
    "        self.image_size = image_size\n",
    "        self.images_path = images_path\n",
    "        self.masks_path = masks_path\n",
    "        self.batch_size = batch_size\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if(index+1)*self.batch_size > len(self.images_path):\n",
    "            self.batch_size = len(self.images_path) - index*self.batch_size\n",
    "        images_path = self.images_path[index*self.batch_size : (index+1)*self.batch_size]\n",
    "        masks_path = self.masks_path[index*self.batch_size : (index+1)*self.batch_size]\n",
    "\n",
    "        images_batch = []\n",
    "        masks_batch = []\n",
    "\n",
    "        for i in range(len(images_path)):\n",
    "            # Read image and mask\n",
    "            image = parse_image(images_path[i], self.image_size)\n",
    "            mask = parse_mask(masks_path[i], self.image_size)\n",
    "\n",
    "            images_batch.append(image)\n",
    "#             mask=np.where(mask>1,1,mask)\n",
    "            masks_batch.append(mask)\n",
    "\n",
    "        return np.array(images_batch), np.array(masks_batch)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.images_path)/float(self.batch_size)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1637a4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_paths = sorted(glob.glob(\"/home/centos/rabeea/maski/cate2/images/*.jpg\"))\n",
    "train_masks_paths = sorted(glob.glob(\"/home/centos/rabeea/maski/cate2/masks/*.bmp\"))\n",
    "\n",
    "\n",
    "\n",
    "valid_data_paths = sorted(glob.glob(\"/home/centos/rabeea/maski/cate2/images/*.jpg\"))\n",
    "valid_masks_paths = sorted(glob.glob(\"/home/centos/rabeea/maski/cate2/masks/*.bmp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa99274",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 1120\n",
    "batch_size = 1\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "train_steps = len(train_data_paths)//batch_size\n",
    "valid_steps = len(valid_data_paths)//batch_size\n",
    "\n",
    "## Generator\n",
    "train_gen = DataGen(image_size, train_data_paths,train_masks_paths, batch_size=batch_size)\n",
    "valid_gen = DataGen(image_size,valid_data_paths, valid_masks_paths, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cdc823",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen.__getitem__(20)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97692f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen.__getitem__(20)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9a5666",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=Model_2D.fit(train_gen,\n",
    "                            validation_data=valid_gen,epochs=500,shuffle=True\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b32fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_2D.save('/home/centos/rabeea/maski/2Dunet_teeth_cate2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817d7926",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "Model_2D = load_model('/home/centos/rabeea/maski/2Dunet_teeth_cate3.h5', compile=False)\n",
    "# my_model=Model_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed26a4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the training and validation IoU and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac4a60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['dice_coe']\n",
    "val_acc = history.history['val_dice_coe']\n",
    "\n",
    "plt.plot(epochs, acc, 'y', label='Training Dice coefficient')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation Dice Coefficient')\n",
    "plt.title('Training and validation Dice coefficient')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Dice Coefficient')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d81358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppath= [n.split('/')[-1].split('.')[0] for n in sorted(glob.glob(\"/home/centos/rabeea/maski/cate3/instance_masks/*.bmp\"))]\n",
    "data_paths = []\n",
    "masks_paths = []\n",
    "for p in (ppath):\n",
    "    data_paths.append(os.path.join('/home/centos/rabeea/maski/cate3/images/',(p+'.jpg'))) \n",
    "    masks_paths.append(os.path.join('/home/centos/rabeea/maski/cate3/masks/',(p+'.bmp'))) \n",
    "for k in range(len(data_paths)):\n",
    "    test_data_paths=[]\n",
    "    test_masks_paths=[]\n",
    "    test_data_paths.append(data_paths[k])\n",
    "    test_masks_paths.append(masks_paths[k])\n",
    "    image_size = 1120\n",
    "    batch_size = 1\n",
    "    test_steps = len(test_data_paths)//batch_size\n",
    "    test_gen = DataGen(image_size, test_data_paths,test_masks_paths, batch_size=batch_size)\n",
    "    y_pred=Model_2D.predict(test_gen.__getitem__(0)[0])\n",
    "    y_pred_argmax=np.where(y_pred>0.8,1,0)\n",
    "    pred=y_pred_argmax[0,:,:,0].astype('float32')\n",
    "    pred= cv2.resize(pred, (1991, 1127))\n",
    "    pred=np.where(pred>0,255,0).astype(np.uint8)\n",
    "#     plt.imshow(pred)\n",
    "#     plt.show()\n",
    "#     print((pred))\n",
    "    im=Image.fromarray(pred)\n",
    "    im.save(os.path.join('/home/centos/rabeea/maski/cate3/pred_masks/',(data_paths[k].split('/')[-1].split('.')[0]+'.bmp')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02137c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_paths = sorted(glob.glob(\"/home/centos/rabeea/maski/cate2/images/*.jpg\"))[0:1]\n",
    "test_masks_paths = sorted(glob.glob(\"/home/centos/rabeea/maski/cate2/masks/*.bmp\"))[0:1]\n",
    "image_size = 1120\n",
    "batch_size = 1\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "test_steps = len(test_data_paths)//batch_size\n",
    "\n",
    "## Generator\n",
    "test_gen = DataGen(image_size, test_data_paths,test_masks_paths, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30df3f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2b108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(test_gen.__getitem__(0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9e896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=Model_2D.predict(train_gen.__getitem__(19)[0])\n",
    "y_pred_argmax=np.where(y_pred>0.8,1,0)\n",
    "true_msk=train_gen.__getitem__(19)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdaec38",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(y_pred_argmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d95469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt= np.zeros([128,128],dtype=int)\n",
    "# pred= np.zeros([128,128],dtype=int)\n",
    "# for i in range (33):\n",
    "#     gt= np.where(true_msk[0,:,:,i]==1,i,gt)\n",
    "#     pred= np.where(y_pred_argmax[0,:,:,i]==1,i,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6792858",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(true_msk[0,:,:,0],'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f065a1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(y_pred_argmax[0,:,:,0],'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0318adc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=y_pred_argmax[0,:,:,0].astype('float32')\n",
    "pred= cv2.resize(pred, (1991, 1127))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6791a4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6008c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt=true_msk[0,:,:,0].astype('float32')\n",
    "gt= cv2.resize(gt, (1991, 1127) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad17c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(gt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ca3807",
   "metadata": {},
   "outputs": [],
   "source": [
    "original= (train_gen.__getitem__(19)[0][0]/255).astype('float32')\n",
    "original= cv2.resize(original, (1991, 1127), interpolation= cv2.INTER_CUBIC )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3033605",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "# plt.imshow((train_gen.__getitem__(5)[0][0]/255))\n",
    "plt.imshow(original)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aa1f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "image=original.copy()\n",
    "pred=np.where(pred>0,True,False)\n",
    "image[pred]= (0,0,255)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ce7873",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "image=original.copy()\n",
    "gt=np.where(gt>0,True,False)\n",
    "image[gt]= (0,0,255)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091036e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new=Image.blend(original, image, .7)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(new)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4808fa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c572f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train_gen.__getitem__(5)[0][0]/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855c79fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "image[mask] = (0, 0, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da355ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(train_gen.__getitem__(2)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f58673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt=gt.astype('float32')\n",
    "gt= cv2.resize(gt, (1991, 1127))\n",
    "original= cv2.resize(train_gen.__getitem__(2)[0][0].astype('float32'), (1991,1127))\n",
    "plt.figure(figsize=(10,10))\n",
    "# plt.imshow(original,alpha=0.5)\n",
    "plt.imshow(gt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2841417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e25b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b2ae27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": " beea38 ",
   "language": "python",
   "name": "beea38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
